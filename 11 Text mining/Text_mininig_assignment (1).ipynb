{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18c828d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\R\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np               \n",
    "import pandas as pd              \n",
    "import string \n",
    "import nltk\n",
    "#The VADER lexicon is a list of words with associated sentiment scores, helping in sentiment analysis.\n",
    "nltk.download('vader_lexicon')\n",
    "import spacy      #Imports the spaCy library, a natural language processing (NLP) library.                 \n",
    "from matplotlib.pyplot import imread\n",
    "from matplotlib import pyplot as plt\n",
    "from wordcloud import wordcloud\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1538afb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp=spacy.load('en_core_web_sm')\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f20f3b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@kunalb11 I’m an alien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>@ID_AA_Carmack Ray tracing on Cyberpunk with H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>@joerogan @Spotify Great interview!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@gtera27 Doge is underestimated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>@teslacn Congratulations Tesla China for amazi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>1995</td>\n",
       "      <td>@flcnhvy True, it sounds so surreal, but the n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1996</td>\n",
       "      <td>@PPathole Make sure to read ur terms &amp;amp; con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1997</td>\n",
       "      <td>@TeslaGong @PPathole Samwise Gamgee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1998</td>\n",
       "      <td>@PPathole Altho Dumb and Dumber is &lt;U+0001F525...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1999</td>\n",
       "      <td>Progress update August 28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               Text\n",
       "0              1                             @kunalb11 I’m an alien\n",
       "1              2  @ID_AA_Carmack Ray tracing on Cyberpunk with H...\n",
       "2              3                @joerogan @Spotify Great interview!\n",
       "3              4                    @gtera27 Doge is underestimated\n",
       "4              5  @teslacn Congratulations Tesla China for amazi...\n",
       "...          ...                                                ...\n",
       "1994        1995  @flcnhvy True, it sounds so surreal, but the n...\n",
       "1995        1996  @PPathole Make sure to read ur terms &amp; con...\n",
       "1996        1997                @TeslaGong @PPathole Samwise Gamgee\n",
       "1997        1998  @PPathole Altho Dumb and Dumber is <U+0001F525...\n",
       "1998        1999                          Progress update August 28\n",
       "\n",
       "[1999 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df=pd.read_csv(\"Elon_musk.csv\",encoding='cp1252')\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c3c2ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1999"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ccbafc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                  @kunalb11 I’m an alien\n",
       "1       @ID_AA_Carmack Ray tracing on Cyberpunk with H...\n",
       "2                     @joerogan @Spotify Great interview!\n",
       "3                         @gtera27 Doge is underestimated\n",
       "4       @teslacn Congratulations Tesla China for amazi...\n",
       "                              ...                        \n",
       "1994    @flcnhvy True, it sounds so surreal, but the n...\n",
       "1995    @PPathole Make sure to read ur terms &amp; con...\n",
       "1996                  @TeslaGong @PPathole Samwise Gamgee\n",
       "1997    @PPathole Altho Dumb and Dumber is <U+0001F525...\n",
       "1998                            Progress update August 28\n",
       "Name: Text, Length: 1999, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df.Text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0f1d54",
   "metadata": {},
   "source": [
    "## text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "907774cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@kunalb11 I’m an alien',\n",
       " '@ID_AA_Carmack Ray tracing on Cyberpunk with HDR is next-level. Have you tried it?',\n",
       " '@joerogan @Spotify Great interview!',\n",
       " '@gtera27 Doge is underestimated',\n",
       " '@teslacn Congratulations Tesla China for amazing execution last year. Now on to the next for even more!!',\n",
       " 'Happy New Year of the Ox! https://t.co/9WFKMYu2oj',\n",
       " 'Frodo was the underdoge,\\nAll thought he would fail,\\nHimself most of all. https://t.co/zGxJFDzzrM',\n",
       " '@OwenSparks_ @flcnhvy @anonyx10 Haha thanks :)',\n",
       " '@flcnhvy @anonyx10 Indeed! Tweets definitely do not represent real-world time allocation.',\n",
       " 'The most entertaining outcome is the most likely']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = [x.strip() for x in df.Text] # remove both the leading and the trailing characters\n",
    "df_2 = [x for x in df_1 if x] # removes empty strings, because they are considered in Python as False\n",
    "df_2[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3e0026",
   "metadata": {},
   "source": [
    "### Removing punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2e432a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re #regular expression\n",
    "import string\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub(\"[0-9\" \"]+\",\" \",text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = re.sub('[‘’“”…]', '', text)\n",
    "    return text\n",
    "clean = lambda x: clean_text(x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6137117f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                     kunalb  im an alien\n",
       "1       idaacarmack ray tracing on cyberpunk with hdr ...\n",
       "2                        joerogan spotify great interview\n",
       "3                           gtera  doge is underestimated\n",
       "4       teslacn congratulations tesla china for amazin...\n",
       "                              ...                        \n",
       "1994    flcnhvy true it sounds so surreal but the nega...\n",
       "1995    ppathole make sure to read ur terms amp condit...\n",
       "1996                    teslagong ppathole samwise gamgee\n",
       "1997                   ppathole altho dumb and dumber is \n",
       "1998                             progress update august  \n",
       "Name: text, Length: 1999, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df['text'] = df.Text.apply(clean)\n",
    "\n",
    "df['text']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23664810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@kunalb11 I’m an alien</td>\n",
       "      <td>kunalb  im an alien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>@ID_AA_Carmack Ray tracing on Cyberpunk with H...</td>\n",
       "      <td>idaacarmack ray tracing on cyberpunk with hdr ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>@joerogan @Spotify Great interview!</td>\n",
       "      <td>joerogan spotify great interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@gtera27 Doge is underestimated</td>\n",
       "      <td>gtera  doge is underestimated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>@teslacn Congratulations Tesla China for amazi...</td>\n",
       "      <td>teslacn congratulations tesla china for amazin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>1995</td>\n",
       "      <td>@flcnhvy True, it sounds so surreal, but the n...</td>\n",
       "      <td>flcnhvy true it sounds so surreal but the nega...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1996</td>\n",
       "      <td>@PPathole Make sure to read ur terms &amp;amp; con...</td>\n",
       "      <td>ppathole make sure to read ur terms amp condit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1997</td>\n",
       "      <td>@TeslaGong @PPathole Samwise Gamgee</td>\n",
       "      <td>teslagong ppathole samwise gamgee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1998</td>\n",
       "      <td>@PPathole Altho Dumb and Dumber is &lt;U+0001F525...</td>\n",
       "      <td>ppathole altho dumb and dumber is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1999</td>\n",
       "      <td>Progress update August 28</td>\n",
       "      <td>progress update august</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1999 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               Text  \\\n",
       "0              1                             @kunalb11 I’m an alien   \n",
       "1              2  @ID_AA_Carmack Ray tracing on Cyberpunk with H...   \n",
       "2              3                @joerogan @Spotify Great interview!   \n",
       "3              4                    @gtera27 Doge is underestimated   \n",
       "4              5  @teslacn Congratulations Tesla China for amazi...   \n",
       "...          ...                                                ...   \n",
       "1994        1995  @flcnhvy True, it sounds so surreal, but the n...   \n",
       "1995        1996  @PPathole Make sure to read ur terms &amp; con...   \n",
       "1996        1997                @TeslaGong @PPathole Samwise Gamgee   \n",
       "1997        1998  @PPathole Altho Dumb and Dumber is <U+0001F525...   \n",
       "1998        1999                          Progress update August 28   \n",
       "\n",
       "                                                   text  \n",
       "0                                   kunalb  im an alien  \n",
       "1     idaacarmack ray tracing on cyberpunk with hdr ...  \n",
       "2                      joerogan spotify great interview  \n",
       "3                         gtera  doge is underestimated  \n",
       "4     teslacn congratulations tesla china for amazin...  \n",
       "...                                                 ...  \n",
       "1994  flcnhvy true it sounds so surreal but the nega...  \n",
       "1995  ppathole make sure to read ur terms amp condit...  \n",
       "1996                  teslagong ppathole samwise gamgee  \n",
       "1997                 ppathole altho dumb and dumber is   \n",
       "1998                           progress update august    \n",
       "\n",
       "[1999 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63c1b0e",
   "metadata": {},
   "source": [
    "### Stop Words removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b86b565e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "stop_word=pd.read_csv(\"stop.txt\",header=None)\n",
    "\n",
    "st_word = [i for i in stop_word[0]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b7a2a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\R\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32a96d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750\n"
     ]
    }
   ],
   "source": [
    "stop= stopwords.words('english')\n",
    "my_stop_words= stop.copy()\n",
    "#add more stop words\n",
    "for i in st_word:\n",
    "    my_stop_words.append(i)  \n",
    "print(len(my_stop_words))\n",
    "df['text'] = df['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in my_stop_words))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495eca74",
   "metadata": {},
   "source": [
    "### \n",
    "Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a5dfa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adac4f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "def sentiment_scores(text):\n",
    "    \n",
    "    sentiment_dict = sid.polarity_scores(text)\n",
    "    print(\"Overall sentiment dictionary is : \", sentiment_dict)\n",
    "    print(\"sentence was rated as \", sentiment_dict['neg']*100, \"% Negative\")\n",
    "    print(\"sentence was rated as \", sentiment_dict['neu']*100, \"% Neutral\")\n",
    "    print(\"sentence was rated as \", sentiment_dict['pos']*100, \"% Positive\")\n",
    "    print(\"Sentence Overall Rated As\", end = \" \")\n",
    " \n",
    "    # decide sentiment as positive, negative and neutral\n",
    "    if sentiment_dict['compound'] >= 0.05 :\n",
    "        print(\"Positive\")\n",
    "        \n",
    "    elif sentiment_dict['compound'] <= - 0.05 :\n",
    "        print(\"Negative\")\n",
    " \n",
    "    else :\n",
    "        print(\"Neutral\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f3a067e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'teslacn congratulations tesla china amazing execution year'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=SentimentIntensityAnalyzer().polarity_scores(df['text'][2])\n",
    "\n",
    "x=SentimentIntensityAnalyzer().polarity_scores(df['text'][4])\n",
    "df['text'][4]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e8339aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.394, 'pos': 0.606, 'compound': 0.8271}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "122d4a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>text</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@kunalb11 I’m an alien</td>\n",
       "      <td>kunalb im alien</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>@ID_AA_Carmack Ray tracing on Cyberpunk with H...</td>\n",
       "      <td>idaacarmack ray tracing cyberpunk hdr nextlevel</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>@joerogan @Spotify Great interview!</td>\n",
       "      <td>joerogan spotify great interview</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.423, 'pos': 0.577, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@gtera27 Doge is underestimated</td>\n",
       "      <td>gtera doge underestimated</td>\n",
       "      <td>{'neg': 0.512, 'neu': 0.488, 'pos': 0.0, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>@teslacn Congratulations Tesla China for amazi...</td>\n",
       "      <td>teslacn congratulations tesla china amazing ex...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.394, 'pos': 0.606, 'comp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               Text  \\\n",
       "0           1                             @kunalb11 I’m an alien   \n",
       "1           2  @ID_AA_Carmack Ray tracing on Cyberpunk with H...   \n",
       "2           3                @joerogan @Spotify Great interview!   \n",
       "3           4                    @gtera27 Doge is underestimated   \n",
       "4           5  @teslacn Congratulations Tesla China for amazi...   \n",
       "\n",
       "                                                text  \\\n",
       "0                                    kunalb im alien   \n",
       "1    idaacarmack ray tracing cyberpunk hdr nextlevel   \n",
       "2                   joerogan spotify great interview   \n",
       "3                          gtera doge underestimated   \n",
       "4  teslacn congratulations tesla china amazing ex...   \n",
       "\n",
       "                                              scores  \n",
       "0  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "1  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "2  {'neg': 0.0, 'neu': 0.423, 'pos': 0.577, 'comp...  \n",
       "3  {'neg': 0.512, 'neu': 0.488, 'pos': 0.0, 'comp...  \n",
       "4  {'neg': 0.0, 'neu': 0.394, 'pos': 0.606, 'comp...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df['scores']=df['text'].apply(lambda text: sid.polarity_scores(text))\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb5d3e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>text</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@kunalb11 I’m an alien</td>\n",
       "      <td>kunalb im alien</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>@ID_AA_Carmack Ray tracing on Cyberpunk with H...</td>\n",
       "      <td>idaacarmack ray tracing cyberpunk hdr nextlevel</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>@joerogan @Spotify Great interview!</td>\n",
       "      <td>joerogan spotify great interview</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.423, 'pos': 0.577, 'comp...</td>\n",
       "      <td>0.6249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@gtera27 Doge is underestimated</td>\n",
       "      <td>gtera doge underestimated</td>\n",
       "      <td>{'neg': 0.512, 'neu': 0.488, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-0.2732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>@teslacn Congratulations Tesla China for amazi...</td>\n",
       "      <td>teslacn congratulations tesla china amazing ex...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.394, 'pos': 0.606, 'comp...</td>\n",
       "      <td>0.8271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               Text  \\\n",
       "0           1                             @kunalb11 I’m an alien   \n",
       "1           2  @ID_AA_Carmack Ray tracing on Cyberpunk with H...   \n",
       "2           3                @joerogan @Spotify Great interview!   \n",
       "3           4                    @gtera27 Doge is underestimated   \n",
       "4           5  @teslacn Congratulations Tesla China for amazi...   \n",
       "\n",
       "                                                text  \\\n",
       "0                                    kunalb im alien   \n",
       "1    idaacarmack ray tracing cyberpunk hdr nextlevel   \n",
       "2                   joerogan spotify great interview   \n",
       "3                          gtera doge underestimated   \n",
       "4  teslacn congratulations tesla china amazing ex...   \n",
       "\n",
       "                                              scores  compound  \n",
       "0  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000  \n",
       "1  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000  \n",
       "2  {'neg': 0.0, 'neu': 0.423, 'pos': 0.577, 'comp...    0.6249  \n",
       "3  {'neg': 0.512, 'neu': 0.488, 'pos': 0.0, 'comp...   -0.2732  \n",
       "4  {'neg': 0.0, 'neu': 0.394, 'pos': 0.606, 'comp...    0.8271  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['compound']=df['scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08b31709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>text</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@kunalb11 I’m an alien</td>\n",
       "      <td>kunalb im alien</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>@ID_AA_Carmack Ray tracing on Cyberpunk with H...</td>\n",
       "      <td>idaacarmack ray tracing cyberpunk hdr nextlevel</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>@joerogan @Spotify Great interview!</td>\n",
       "      <td>joerogan spotify great interview</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.423, 'pos': 0.577, 'comp...</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@gtera27 Doge is underestimated</td>\n",
       "      <td>gtera doge underestimated</td>\n",
       "      <td>{'neg': 0.512, 'neu': 0.488, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-0.2732</td>\n",
       "      <td>0.512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>@teslacn Congratulations Tesla China for amazi...</td>\n",
       "      <td>teslacn congratulations tesla china amazing ex...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.394, 'pos': 0.606, 'comp...</td>\n",
       "      <td>0.8271</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               Text  \\\n",
       "0           1                             @kunalb11 I’m an alien   \n",
       "1           2  @ID_AA_Carmack Ray tracing on Cyberpunk with H...   \n",
       "2           3                @joerogan @Spotify Great interview!   \n",
       "3           4                    @gtera27 Doge is underestimated   \n",
       "4           5  @teslacn Congratulations Tesla China for amazi...   \n",
       "\n",
       "                                                text  \\\n",
       "0                                    kunalb im alien   \n",
       "1    idaacarmack ray tracing cyberpunk hdr nextlevel   \n",
       "2                   joerogan spotify great interview   \n",
       "3                          gtera doge underestimated   \n",
       "4  teslacn congratulations tesla china amazing ex...   \n",
       "\n",
       "                                              scores  compound    neg  \n",
       "0  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000  0.000  \n",
       "1  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000  0.000  \n",
       "2  {'neg': 0.0, 'neu': 0.423, 'pos': 0.577, 'comp...    0.6249  0.000  \n",
       "3  {'neg': 0.512, 'neu': 0.488, 'pos': 0.0, 'comp...   -0.2732  0.512  \n",
       "4  {'neg': 0.0, 'neu': 0.394, 'pos': 0.606, 'comp...    0.8271  0.000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df['neg']=df['scores'].apply(lambda score_dict: score_dict['neg'])\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "756c952c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>text</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@kunalb11 I’m an alien</td>\n",
       "      <td>kunalb im alien</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>@ID_AA_Carmack Ray tracing on Cyberpunk with H...</td>\n",
       "      <td>idaacarmack ray tracing cyberpunk hdr nextlevel</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>@joerogan @Spotify Great interview!</td>\n",
       "      <td>joerogan spotify great interview</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.423, 'pos': 0.577, 'comp...</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@gtera27 Doge is underestimated</td>\n",
       "      <td>gtera doge underestimated</td>\n",
       "      <td>{'neg': 0.512, 'neu': 0.488, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-0.2732</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>@teslacn Congratulations Tesla China for amazi...</td>\n",
       "      <td>teslacn congratulations tesla china amazing ex...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.394, 'pos': 0.606, 'comp...</td>\n",
       "      <td>0.8271</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               Text  \\\n",
       "0           1                             @kunalb11 I’m an alien   \n",
       "1           2  @ID_AA_Carmack Ray tracing on Cyberpunk with H...   \n",
       "2           3                @joerogan @Spotify Great interview!   \n",
       "3           4                    @gtera27 Doge is underestimated   \n",
       "4           5  @teslacn Congratulations Tesla China for amazi...   \n",
       "\n",
       "                                                text  \\\n",
       "0                                    kunalb im alien   \n",
       "1    idaacarmack ray tracing cyberpunk hdr nextlevel   \n",
       "2                   joerogan spotify great interview   \n",
       "3                          gtera doge underestimated   \n",
       "4  teslacn congratulations tesla china amazing ex...   \n",
       "\n",
       "                                              scores  compound    neg    pos  \n",
       "0  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000  0.000  0.000  \n",
       "1  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000  0.000  0.000  \n",
       "2  {'neg': 0.0, 'neu': 0.423, 'pos': 0.577, 'comp...    0.6249  0.000  0.577  \n",
       "3  {'neg': 0.512, 'neu': 0.488, 'pos': 0.0, 'comp...   -0.2732  0.512  0.000  \n",
       "4  {'neg': 0.0, 'neu': 0.394, 'pos': 0.606, 'comp...    0.8271  0.000  0.606  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df['pos']=df['scores'].apply(lambda score_dict: score_dict['pos'])\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5526fc10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>text</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "      <th>neu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@kunalb11 I’m an alien</td>\n",
       "      <td>kunalb im alien</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>@ID_AA_Carmack Ray tracing on Cyberpunk with H...</td>\n",
       "      <td>idaacarmack ray tracing cyberpunk hdr nextlevel</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>@joerogan @Spotify Great interview!</td>\n",
       "      <td>joerogan spotify great interview</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.423, 'pos': 0.577, 'comp...</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@gtera27 Doge is underestimated</td>\n",
       "      <td>gtera doge underestimated</td>\n",
       "      <td>{'neg': 0.512, 'neu': 0.488, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-0.2732</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>@teslacn Congratulations Tesla China for amazi...</td>\n",
       "      <td>teslacn congratulations tesla china amazing ex...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.394, 'pos': 0.606, 'comp...</td>\n",
       "      <td>0.8271</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               Text  \\\n",
       "0           1                             @kunalb11 I’m an alien   \n",
       "1           2  @ID_AA_Carmack Ray tracing on Cyberpunk with H...   \n",
       "2           3                @joerogan @Spotify Great interview!   \n",
       "3           4                    @gtera27 Doge is underestimated   \n",
       "4           5  @teslacn Congratulations Tesla China for amazi...   \n",
       "\n",
       "                                                text  \\\n",
       "0                                    kunalb im alien   \n",
       "1    idaacarmack ray tracing cyberpunk hdr nextlevel   \n",
       "2                   joerogan spotify great interview   \n",
       "3                          gtera doge underestimated   \n",
       "4  teslacn congratulations tesla china amazing ex...   \n",
       "\n",
       "                                              scores  compound    neg    pos  \\\n",
       "0  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000  0.000  0.000   \n",
       "1  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000  0.000  0.000   \n",
       "2  {'neg': 0.0, 'neu': 0.423, 'pos': 0.577, 'comp...    0.6249  0.000  0.577   \n",
       "3  {'neg': 0.512, 'neu': 0.488, 'pos': 0.0, 'comp...   -0.2732  0.512  0.000   \n",
       "4  {'neg': 0.0, 'neu': 0.394, 'pos': 0.606, 'comp...    0.8271  0.000  0.606   \n",
       "\n",
       "     neu  \n",
       "0  1.000  \n",
       "1  1.000  \n",
       "2  0.423  \n",
       "3  0.488  \n",
       "4  0.394  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df['neu']=df['scores'].apply(lambda score_dict: score_dict['neu'])\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67aab461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>text</th>\n",
       "      <th>scores</th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>pos</th>\n",
       "      <th>neu</th>\n",
       "      <th>comp_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@kunalb11 I’m an alien</td>\n",
       "      <td>kunalb im alien</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>@ID_AA_Carmack Ray tracing on Cyberpunk with H...</td>\n",
       "      <td>idaacarmack ray tracing cyberpunk hdr nextlevel</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>@joerogan @Spotify Great interview!</td>\n",
       "      <td>joerogan spotify great interview</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.423, 'pos': 0.577, 'comp...</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.423</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>@gtera27 Doge is underestimated</td>\n",
       "      <td>gtera doge underestimated</td>\n",
       "      <td>{'neg': 0.512, 'neu': 0.488, 'pos': 0.0, 'comp...</td>\n",
       "      <td>-0.2732</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.488</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>@teslacn Congratulations Tesla China for amazi...</td>\n",
       "      <td>teslacn congratulations tesla china amazing ex...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.394, 'pos': 0.606, 'comp...</td>\n",
       "      <td>0.8271</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.394</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               Text  \\\n",
       "0           1                             @kunalb11 I’m an alien   \n",
       "1           2  @ID_AA_Carmack Ray tracing on Cyberpunk with H...   \n",
       "2           3                @joerogan @Spotify Great interview!   \n",
       "3           4                    @gtera27 Doge is underestimated   \n",
       "4           5  @teslacn Congratulations Tesla China for amazi...   \n",
       "\n",
       "                                                text  \\\n",
       "0                                    kunalb im alien   \n",
       "1    idaacarmack ray tracing cyberpunk hdr nextlevel   \n",
       "2                   joerogan spotify great interview   \n",
       "3                          gtera doge underestimated   \n",
       "4  teslacn congratulations tesla china amazing ex...   \n",
       "\n",
       "                                              scores  compound    neg    pos  \\\n",
       "0  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000  0.000  0.000   \n",
       "1  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...    0.0000  0.000  0.000   \n",
       "2  {'neg': 0.0, 'neu': 0.423, 'pos': 0.577, 'comp...    0.6249  0.000  0.577   \n",
       "3  {'neg': 0.512, 'neu': 0.488, 'pos': 0.0, 'comp...   -0.2732  0.512  0.000   \n",
       "4  {'neg': 0.0, 'neu': 0.394, 'pos': 0.606, 'comp...    0.8271  0.000  0.606   \n",
       "\n",
       "     neu comp_score  \n",
       "0  1.000        pos  \n",
       "1  1.000        pos  \n",
       "2  0.423        pos  \n",
       "3  0.488        neg  \n",
       "4  0.394        pos  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comp_score']=df['compound'].apply(lambda c: 'pos' if c >= 0 else 'neg')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84956f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000    1734\n",
       "0.231       6\n",
       "0.252       5\n",
       "0.247       5\n",
       "0.097       5\n",
       "         ... \n",
       "0.206       1\n",
       "0.090       1\n",
       "0.605       1\n",
       "0.397       1\n",
       "0.220       1\n",
       "Name: neg, Length: 172, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['neg'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8fef5a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000    1277\n",
       "0.375      16\n",
       "0.672      14\n",
       "0.412      12\n",
       "0.600      11\n",
       "         ... \n",
       "0.649       1\n",
       "0.238       1\n",
       "0.341       1\n",
       "0.709       1\n",
       "0.317       1\n",
       "Name: pos, Length: 309, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df['pos'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4646c3ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.0000    1114\n",
       " 0.6249      54\n",
       " 0.4588      49\n",
       " 0.4215      46\n",
       " 0.4404      42\n",
       "           ... \n",
       " 0.7891       1\n",
       "-0.4912       1\n",
       " 0.7269       1\n",
       " 0.8155       1\n",
       "-0.7351       1\n",
       "Name: compound, Length: 141, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df['compound'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09db6ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.000    1106\n",
       "0.625      19\n",
       "0.588      17\n",
       "0.328      14\n",
       "0.833      12\n",
       "         ... \n",
       "0.654       1\n",
       "0.524       1\n",
       "0.522       1\n",
       "0.808       1\n",
       "0.380       1\n",
       "Name: neu, Length: 330, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['neu'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befc26da",
   "metadata": {},
   "source": [
    "### \n",
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5899ba48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107235"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "text_1= [x.strip() for x in df.text] # remove both the leading and the trailing characters\n",
    "text_2= [x for x in text_1 if x] # removes empty strings, because they are considered in Python as False\n",
    "# Joining the list into one string/text\n",
    "text_3 = ' '.join(text_2)\n",
    "len(text_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6de83c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\R\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['kunalb',\n",
       " 'im',\n",
       " 'alien',\n",
       " 'idaacarmack',\n",
       " 'ray',\n",
       " 'tracing',\n",
       " 'cyberpunk',\n",
       " 'hdr',\n",
       " 'nextlevel',\n",
       " 'joerogan',\n",
       " 'spotify',\n",
       " 'great',\n",
       " 'interview',\n",
       " 'gtera',\n",
       " 'doge',\n",
       " 'underestimated',\n",
       " 'teslacn',\n",
       " 'congratulations',\n",
       " 'tesla',\n",
       " 'china',\n",
       " 'amazing',\n",
       " 'execution',\n",
       " 'year',\n",
       " 'happy',\n",
       " 'year',\n",
       " 'ox',\n",
       " 'httpstco',\n",
       " 'wfkmyu',\n",
       " 'oj',\n",
       " 'frodo',\n",
       " 'underdogeall',\n",
       " 'thought',\n",
       " 'failhimself',\n",
       " 'httpstcozgxjfdzzrm',\n",
       " 'owensparks',\n",
       " 'flcnhvy',\n",
       " 'anonyx',\n",
       " 'haha',\n",
       " 'flcnhvy',\n",
       " 'anonyx',\n",
       " 'tweets',\n",
       " 'represent',\n",
       " 'realworld',\n",
       " 'time',\n",
       " 'allocation',\n",
       " 'entertaining',\n",
       " 'outcome',\n",
       " 'givedirectly',\n",
       " 'agree',\n",
       " 'clubhouse',\n",
       " 'kanyewest',\n",
       " 'httpstco',\n",
       " 'rwe',\n",
       " 'uhsts',\n",
       " 'geoffkeighley',\n",
       " 'unrealengine',\n",
       " 'real',\n",
       " 'bought',\n",
       " 'dogecoin',\n",
       " 'lil',\n",
       " 'toddler',\n",
       " 'hodler',\n",
       " 'joshmanmode',\n",
       " 'issues',\n",
       " 'sentencing',\n",
       " 'bit',\n",
       " 'high',\n",
       " 'freewalletorg',\n",
       " 'fixing',\n",
       " 'freewalletorg',\n",
       " 'unlock',\n",
       " 'account',\n",
       " 'astrojordy',\n",
       " 'true',\n",
       " 'power',\n",
       " 'haha',\n",
       " 'httpstcofc',\n",
       " 'uhqsd',\n",
       " 'freewalletorg',\n",
       " 'crypto',\n",
       " 'wallet',\n",
       " 'wont',\n",
       " 'give',\n",
       " 'private',\n",
       " 'keys',\n",
       " 'avoided',\n",
       " 'costs',\n",
       " 'freewalletorg',\n",
       " 'app',\n",
       " 'sucks',\n",
       " 'rt',\n",
       " 'spacex',\n",
       " 'nasa',\n",
       " 'selected',\n",
       " 'falcon',\n",
       " 'heavy',\n",
       " 'launch',\n",
       " 'elements',\n",
       " 'lunar',\n",
       " 'gateway',\n",
       " 'mission',\n",
       " 'httpstco',\n",
       " 'pwt',\n",
       " 'ajtourville',\n",
       " 'blkmdl',\n",
       " 'rationaletienne',\n",
       " 'adamklotz',\n",
       " 'predict',\n",
       " 'cash',\n",
       " 'flow',\n",
       " 'starlink',\n",
       " 'ipo',\n",
       " 'rationaletienne',\n",
       " 'adamklotz',\n",
       " 'starlink',\n",
       " 'staggeringly',\n",
       " 'difficult',\n",
       " 'technical',\n",
       " 'amp',\n",
       " 'economic',\n",
       " 'endeavor',\n",
       " 'httpstco',\n",
       " 'ac',\n",
       " 'skqx',\n",
       " 'rationaletienne',\n",
       " 'adamklotz',\n",
       " 'spacex',\n",
       " 'pass',\n",
       " 'deep',\n",
       " 'chasm',\n",
       " 'negative',\n",
       " 'cash',\n",
       " 'flow',\n",
       " 'year',\n",
       " 'httpstco',\n",
       " 'hdjl',\n",
       " 'idaacarmack',\n",
       " 'lowest',\n",
       " 'cost',\n",
       " 'ton',\n",
       " 'carbon',\n",
       " 'sequestered',\n",
       " 'net',\n",
       " 'product',\n",
       " 'made',\n",
       " 'scalable',\n",
       " 'httpstcoxmyi',\n",
       " 'qwsgw',\n",
       " 'adamklotz',\n",
       " 'meant',\n",
       " 'price',\n",
       " 'countries',\n",
       " 'difference',\n",
       " 'taxes',\n",
       " 'amp',\n",
       " 'shipping',\n",
       " 'tobyliiiiiiiiii',\n",
       " 'intended',\n",
       " 'earth',\n",
       " 'ideas',\n",
       " 'apply',\n",
       " 'mars',\n",
       " 'cryptoshrikar',\n",
       " 'coindesk',\n",
       " 'tesla',\n",
       " 'danzpalmer',\n",
       " 'xprize',\n",
       " 'team',\n",
       " 'manage',\n",
       " 'carbon',\n",
       " 'capture',\n",
       " 'prize',\n",
       " 'httpstcofsw',\n",
       " 'ianl',\n",
       " 'sruhle',\n",
       " 'tesla',\n",
       " 'receives',\n",
       " 'stock',\n",
       " 'comp',\n",
       " 'stockoptions',\n",
       " 'table',\n",
       " 'youre',\n",
       " 'missing',\n",
       " 'back',\n",
       " 'work',\n",
       " 'capybarasurfer',\n",
       " 'mattwallace',\n",
       " 'bit',\n",
       " 'high',\n",
       " 'itsallrisky',\n",
       " 'doge',\n",
       " 'appears',\n",
       " 'inflationary',\n",
       " 'meaningfully',\n",
       " 'fixed',\n",
       " 'coins',\n",
       " 'unit',\n",
       " 'time',\n",
       " 'httpstco',\n",
       " 'uh',\n",
       " 'rarc',\n",
       " 'michaelgalanin',\n",
       " 'kevinmgill',\n",
       " 'wow',\n",
       " 'erdayastronaut',\n",
       " 'michaelhodapp',\n",
       " 'orbital',\n",
       " 'launch',\n",
       " 'tower',\n",
       " 'stack',\n",
       " 'raptors',\n",
       " 'orbit',\n",
       " 'booster',\n",
       " 'improve',\n",
       " 'ship',\n",
       " 'amp',\n",
       " 'booster',\n",
       " 'mass',\n",
       " 'michaelhodapp',\n",
       " 'back',\n",
       " 'work',\n",
       " 'tonight',\n",
       " 'ð',\n",
       " 'ðogecoin',\n",
       " 'instructional',\n",
       " 'videohttpstcoueeocofctb',\n",
       " 'people',\n",
       " 'spoken',\n",
       " 'httpstcox',\n",
       " 'ovmztgo',\n",
       " 'nivetha',\n",
       " 'lexfridman',\n",
       " 'cute',\n",
       " 'univercurious',\n",
       " 'extremely',\n",
       " 'misleading',\n",
       " 'image',\n",
       " 'doesnt',\n",
       " 'reflect',\n",
       " 'true',\n",
       " 'time',\n",
       " 'cost',\n",
       " 'people',\n",
       " 'rain',\n",
       " 'amp',\n",
       " 'pain',\n",
       " 'doge',\n",
       " 'hodl',\n",
       " 'rainforests',\n",
       " 'finally',\n",
       " 'httpstcogf',\n",
       " 'rg',\n",
       " 'qoaf',\n",
       " 'itsallrisky',\n",
       " 'fun',\n",
       " 'crypto',\n",
       " 'joshroomsburg',\n",
       " 'snoopdogg',\n",
       " 'genesimmons',\n",
       " 'simplicity',\n",
       " 'genius',\n",
       " 'astrogdogg',\n",
       " 'spacex',\n",
       " 'yup',\n",
       " 'jbuttermost',\n",
       " 'dogecoinrich',\n",
       " 'wapodavenport',\n",
       " 'true',\n",
       " 'dogecoinrich',\n",
       " 'flcnhvy',\n",
       " 'astrojordy',\n",
       " 'easy',\n",
       " 'decades',\n",
       " 'intense',\n",
       " 'work',\n",
       " 'notes',\n",
       " 'emails',\n",
       " 'texts',\n",
       " 'astrojordy',\n",
       " 'lessons',\n",
       " 'learned',\n",
       " 'earth',\n",
       " 'mars',\n",
       " 'time',\n",
       " 'story',\n",
       " 'tesla',\n",
       " 'amp',\n",
       " 'spacex',\n",
       " 'theonion',\n",
       " 'read',\n",
       " 'thebabylonbee',\n",
       " 'great',\n",
       " 'kingdom',\n",
       " 'httpstcoje',\n",
       " 'ei',\n",
       " 'hmv',\n",
       " 'dumdin',\n",
       " 'grimezsz',\n",
       " 'havent',\n",
       " 'heard',\n",
       " 'years',\n",
       " 'grimezsz',\n",
       " 'dogecake',\n",
       " 'yolthttpstcocnof',\n",
       " 'yjpf',\n",
       " 'kristennetten',\n",
       " 'damian',\n",
       " 'kristennetten',\n",
       " 'yeah',\n",
       " 'owensparks',\n",
       " 'great',\n",
       " 'thing',\n",
       " 'restaurants',\n",
       " 'hang',\n",
       " 'strangers',\n",
       " 'sjm',\n",
       " 'future',\n",
       " 'currency',\n",
       " 'earth',\n",
       " 'redlineshifter',\n",
       " 'scratch',\n",
       " 'wow',\n",
       " 'rationaletienne',\n",
       " 'wonderofscience',\n",
       " 'destiny',\n",
       " 'renatakonkoly',\n",
       " 'teslarati',\n",
       " 'woodhaus',\n",
       " 'franz',\n",
       " 'essential',\n",
       " 'erdayastronaut',\n",
       " 'joshbickett',\n",
       " 'ajtourville',\n",
       " 'spacex',\n",
       " 'ship',\n",
       " 'landing',\n",
       " 'burn',\n",
       " 'clear',\n",
       " 'solution',\n",
       " 'greate',\n",
       " 'httpstcoe',\n",
       " 'wikiugkz',\n",
       " 'adamklotz',\n",
       " 'erdayastronaut',\n",
       " 'joshbickett',\n",
       " 'ajtourville',\n",
       " 'spacex',\n",
       " 'hot',\n",
       " 'gas',\n",
       " 'maneuvering',\n",
       " 'rcs',\n",
       " 'thrusters',\n",
       " 'httpstcovso',\n",
       " 'ioed',\n",
       " 'erdayastronaut',\n",
       " 'joshbickett',\n",
       " 'ajtourville',\n",
       " 'spacex',\n",
       " 'higher',\n",
       " 'isp',\n",
       " 'erdayastronaut',\n",
       " 'joshbickett',\n",
       " 'ajtourville',\n",
       " 'spacex',\n",
       " 'intuitively',\n",
       " 'turbopumpfed',\n",
       " 'raptors',\n",
       " 'mu',\n",
       " 'httpstcolbtg',\n",
       " 'sibuc',\n",
       " 'brendan',\n",
       " 'nasaspaceflight',\n",
       " 'rt',\n",
       " 'spacex',\n",
       " 'falcon',\n",
       " 'launch',\n",
       " 'nasas',\n",
       " 'spherex',\n",
       " 'mission',\n",
       " '–',\n",
       " 'collect',\n",
       " 'data',\n",
       " 'million',\n",
       " 'galaxies',\n",
       " 'explore',\n",
       " 'rt',\n",
       " 'spacex',\n",
       " 'falcon',\n",
       " 'launches',\n",
       " 'starlink',\n",
       " 'satellites',\n",
       " 'orbit',\n",
       " '–',\n",
       " 'mission',\n",
       " 'pad',\n",
       " 'deck',\n",
       " 'httpstco',\n",
       " 'cucbgpnx',\n",
       " 'mikko',\n",
       " 'darudevil',\n",
       " 'true',\n",
       " 'joshbickett',\n",
       " 'ajtourville',\n",
       " 'erdayastronaut',\n",
       " 'spacex',\n",
       " 'yeah',\n",
       " 'default',\n",
       " 'engine',\n",
       " 'lever',\n",
       " 'arm',\n",
       " 'shut',\n",
       " 'good',\n",
       " 'ajtourville',\n",
       " 'erdayastronaut',\n",
       " 'spacex',\n",
       " 'engines',\n",
       " 'min',\n",
       " 'throttle',\n",
       " 'point',\n",
       " 'flameout',\n",
       " 'risk',\n",
       " 'la',\n",
       " 'httpstcothniyssnwn',\n",
       " 'adamklotz',\n",
       " 'erdayastronaut',\n",
       " 'spacex',\n",
       " 'erdayastronaut',\n",
       " 'spacex',\n",
       " 'foolish',\n",
       " 'start',\n",
       " 'engines',\n",
       " 'amp',\n",
       " 'immediately',\n",
       " 'shut',\n",
       " 'needed',\n",
       " 'land',\n",
       " 'memedestroyer',\n",
       " 'shorts',\n",
       " 'commandercruz',\n",
       " 'happen',\n",
       " 'sandstorm',\n",
       " 'masterpiece',\n",
       " 'madoverlord',\n",
       " 'dumb',\n",
       " 'time',\n",
       " 'pull',\n",
       " 'method',\n",
       " 'httpstcoj',\n",
       " 'whlrdr',\n",
       " 'lowkey',\n",
       " 'loki',\n",
       " 'highs',\n",
       " 'lows',\n",
       " 'doge',\n",
       " 'gigachad',\n",
       " 'dogecoin',\n",
       " 'peoples',\n",
       " 'crypto',\n",
       " 'ur',\n",
       " 'httpstcoe',\n",
       " 'kf',\n",
       " 'klxb',\n",
       " 'huobiglobal',\n",
       " 'entertaining',\n",
       " 'outcome',\n",
       " 'doge',\n",
       " 'httpstcovviuzwhodt',\n",
       " 'erdayastronaut',\n",
       " 'high',\n",
       " 'seas',\n",
       " 'amp',\n",
       " 'wind',\n",
       " 'tough',\n",
       " 'httpstcobey',\n",
       " 'pefpcj',\n",
       " 'rt',\n",
       " 'spacex',\n",
       " 'watch',\n",
       " 'falcon',\n",
       " 'launch',\n",
       " 'starlink',\n",
       " 'satellites',\n",
       " 'httpstcobjfjlczwdk',\n",
       " 'httpstcoln',\n",
       " 'reesbw',\n",
       " 'twitter',\n",
       " 'filled',\n",
       " 'graffiti',\n",
       " 'art',\n",
       " 'eiraum',\n",
       " 'giga',\n",
       " 'berlin',\n",
       " 'progress',\n",
       " 'httpstcoekpg',\n",
       " 'qcbui',\n",
       " 'hamoon',\n",
       " 'neuralink',\n",
       " 'neuralink',\n",
       " 'working',\n",
       " 'super',\n",
       " 'hard',\n",
       " 'ensure',\n",
       " 'implant',\n",
       " 'safety',\n",
       " 'amp',\n",
       " 'close',\n",
       " 'communication',\n",
       " 'httpstcoyky',\n",
       " 'llpumd',\n",
       " 'rt',\n",
       " 'spacex',\n",
       " 'mission',\n",
       " 'enables',\n",
       " 'access',\n",
       " 'everyday',\n",
       " 'people',\n",
       " 'dream',\n",
       " 'space',\n",
       " 'rt',\n",
       " 'spacex',\n",
       " 'announcing',\n",
       " 'commercial',\n",
       " 'astronaut',\n",
       " 'mission',\n",
       " 'orbit',\n",
       " 'earth',\n",
       " 'aboard',\n",
       " 'dragon',\n",
       " 'httpstcombesvnakad',\n",
       " 'httpstcouklsjffrjk',\n",
       " 'youve',\n",
       " 'worked',\n",
       " 'advanced',\n",
       " 'wearables',\n",
       " 'phones',\n",
       " 'robots',\n",
       " 'skills',\n",
       " 'needed',\n",
       " 'neuralink',\n",
       " 'feels',\n",
       " 'weird',\n",
       " 'helping',\n",
       " 'make',\n",
       " 'good',\n",
       " 'version',\n",
       " 'cyberpunk',\n",
       " 'true',\n",
       " 'working',\n",
       " 'neuralinkshortterm',\n",
       " 'solve',\n",
       " 'brainspine',\n",
       " 'injurieslongterm',\n",
       " 'humanai',\n",
       " 'symbiosis',\n",
       " 'latte',\n",
       " 'httpstcoqrc',\n",
       " 'alads',\n",
       " 'httpstcoxccokojylt',\n",
       " 'clubhouse',\n",
       " 'tonight',\n",
       " 'pm',\n",
       " 'la',\n",
       " 'time',\n",
       " 'erdayastronaut',\n",
       " 'tjcooney',\n",
       " 'lrocket',\n",
       " 'spacex',\n",
       " 'felixschlang',\n",
       " 'marcushousegame',\n",
       " 'tom',\n",
       " 'great',\n",
       " 'stories',\n",
       " 'experim',\n",
       " 'httpstcoteezkiwcmk',\n",
       " 'rt',\n",
       " 'commercialcrew',\n",
       " 'launch',\n",
       " 'alert',\n",
       " 'nasa',\n",
       " 'spacex',\n",
       " 'targeting',\n",
       " 'earlier',\n",
       " 'april',\n",
       " 'launch',\n",
       " 'crew',\n",
       " 'rotation',\n",
       " 'mis',\n",
       " 'erdayastronaut',\n",
       " 'tjcooney',\n",
       " 'lrocket',\n",
       " 'spacex',\n",
       " 'felixschlang',\n",
       " 'marcushousegame',\n",
       " 'big',\n",
       " 'fan',\n",
       " 'methane',\n",
       " 'httpstcomdv',\n",
       " 'vdefyc',\n",
       " 'tjcooney',\n",
       " 'lrocket',\n",
       " 'spacex',\n",
       " 'felixschlang',\n",
       " 'marcushousegame',\n",
       " 'sounds',\n",
       " 'correct',\n",
       " 'tom',\n",
       " 'deserves',\n",
       " 'lot',\n",
       " 'cre',\n",
       " 'httpstcohdri',\n",
       " 'hfa',\n",
       " 'tjcooney',\n",
       " 'lrocket',\n",
       " 'spacex',\n",
       " 'felixschlang',\n",
       " 'marcushousegame',\n",
       " 'tom',\n",
       " 'great',\n",
       " 'amp',\n",
       " 'instrumental',\n",
       " 'developing',\n",
       " 'early',\n",
       " 'vers',\n",
       " 'httpstcoulxtclm',\n",
       " 'ercxspace',\n",
       " 'smvllstvrs',\n",
       " 'tw',\n",
       " 'accelerate',\n",
       " 'unusually',\n",
       " 'fast',\n",
       " 'high',\n",
       " 'tw',\n",
       " 'important',\n",
       " 'reusable',\n",
       " 'httpstcou',\n",
       " 'cprrqj',\n",
       " 'dogg',\n",
       " 'teslaownerssv',\n",
       " 'escaping',\n",
       " 'thebabylonbee',\n",
       " 'read',\n",
       " 'article',\n",
       " 'warm',\n",
       " 'sunny',\n",
       " 'day',\n",
       " 'amp',\n",
       " 'snowy',\n",
       " 'mountains',\n",
       " 'httpstco',\n",
       " 'psyqu',\n",
       " 'beautiful',\n",
       " 'day',\n",
       " 'la',\n",
       " 'httpstcoescjtbzo',\n",
       " 'jaylav',\n",
       " 'yeah',\n",
       " 'dr',\n",
       " 'frankensteen',\n",
       " 'httpstcowdj',\n",
       " 'ujqk',\n",
       " 'younesh',\n",
       " 'guy',\n",
       " 'gave',\n",
       " 'talk',\n",
       " 'spacex',\n",
       " 'flcnhvy',\n",
       " 'halo',\n",
       " 'httpstcopyrcfe',\n",
       " 'xp',\n",
       " 'carnage',\n",
       " 'life',\n",
       " 'hope',\n",
       " 'true',\n",
       " 'tesla',\n",
       " 'spacex',\n",
       " 'thejackbeyer',\n",
       " 'nasaspaceflight',\n",
       " 'cryoproof',\n",
       " 'install',\n",
       " 'engines',\n",
       " 'starship',\n",
       " 'sn',\n",
       " 'amp',\n",
       " 'sn',\n",
       " 'httpstcourtpjn',\n",
       " 'amo',\n",
       " 'retrospect',\n",
       " 'inevitable',\n",
       " 'rgvaerialphotos',\n",
       " 'great',\n",
       " 'shot',\n",
       " 'itsmenieb',\n",
       " 'live',\n",
       " 'sword',\n",
       " 'die',\n",
       " 'sword',\n",
       " 'lexfridman',\n",
       " 'entropy',\n",
       " 'teslaownerssv',\n",
       " 'gamespot',\n",
       " 'buy',\n",
       " 'amp',\n",
       " 'hold',\n",
       " 'companies',\n",
       " 'make',\n",
       " 'goods',\n",
       " 'amp',\n",
       " 'produce',\n",
       " 'services',\n",
       " 'love',\n",
       " 'engineersfeed',\n",
       " 'earth',\n",
       " 'small',\n",
       " 'amp',\n",
       " 'smaller',\n",
       " 'httpstcogtohclgj',\n",
       " 'gamespot',\n",
       " 'cyberpunk',\n",
       " 'hotfixes',\n",
       " 'literally',\n",
       " 'hotfixes',\n",
       " 'great',\n",
       " 'game',\n",
       " 'httpstcoa',\n",
       " 'kmk',\n",
       " 'pegm',\n",
       " 'documentingbtc',\n",
       " 'dollar',\n",
       " 'shorting',\n",
       " 'westcoastbill',\n",
       " 'johnnacrider',\n",
       " 'iupsychdoctor',\n",
       " 'aoc',\n",
       " 'robinhoodapp',\n",
       " 'shopify',\n",
       " 'great',\n",
       " 'spacex',\n",
       " 'ohqwix',\n",
       " 'bnnj',\n",
       " 'bcghvzqxlb',\n",
       " 'wimgrommen',\n",
       " 'wsbchairman',\n",
       " 'economy',\n",
       " '—',\n",
       " 'making',\n",
       " 'products',\n",
       " 'amp',\n",
       " 'providing',\n",
       " 'great',\n",
       " 'services',\n",
       " '—',\n",
       " 'matters',\n",
       " 'iupsychdoctor',\n",
       " 'aoc',\n",
       " 'robinhoodapp',\n",
       " 'tanstaafl',\n",
       " 'small',\n",
       " 'fees',\n",
       " 'fees',\n",
       " 'makes',\n",
       " 'robin',\n",
       " 'httpstcoczrhlolyvo',\n",
       " 'shorty',\n",
       " 'apologistsgive',\n",
       " 'respectget',\n",
       " 'shorty',\n",
       " 'sell',\n",
       " 'houses',\n",
       " 'dont',\n",
       " 'ownu',\n",
       " 'sell',\n",
       " 'cars',\n",
       " 'dont',\n",
       " 'ownbut',\n",
       " 'sell',\n",
       " 'stock',\n",
       " 'dont',\n",
       " 'ownthis',\n",
       " 'bs',\n",
       " '–',\n",
       " 'sh',\n",
       " 'httpstcovjkf',\n",
       " 'bqbod',\n",
       " 'rationaletienne',\n",
       " 'teslavangelist',\n",
       " 'delayslater',\n",
       " 'finishing',\n",
       " 'engineering',\n",
       " 'year',\n",
       " 'production',\n",
       " 'starts',\n",
       " 'year',\n",
       " 'aiming',\n",
       " 'release',\n",
       " 'candidate',\n",
       " 'desig',\n",
       " 'httpstcobfverxpoqu',\n",
       " 'ppathole',\n",
       " 'grimezsz',\n",
       " 'made',\n",
       " 'video',\n",
       " 'aoc',\n",
       " 'robinhoodapp',\n",
       " 'absolutely',\n",
       " 'nasaspaceflight',\n",
       " 'unlike',\n",
       " 'aircraft',\n",
       " 'division',\n",
       " 'fine',\n",
       " 'faa',\n",
       " 'space',\n",
       " 'division',\n",
       " 'fundamentally',\n",
       " 'broken',\n",
       " 'reg',\n",
       " 'httpstcosi',\n",
       " 'axbjbz',\n",
       " 'evankaylor',\n",
       " 'nomad',\n",
       " 'anbuteau',\n",
       " 'esthetics',\n",
       " 'cyberpunk',\n",
       " 'incredible',\n",
       " 'btw',\n",
       " 'interior',\n",
       " 'design',\n",
       " 'trevormahlmann',\n",
       " 'spacex',\n",
       " 'major',\n",
       " 'esthetics',\n",
       " 'improvements',\n",
       " 'coming',\n",
       " 'teslaownerssv',\n",
       " 'dmcryan',\n",
       " 'dmcryan',\n",
       " 'roadster',\n",
       " 'part',\n",
       " 'rocket',\n",
       " 'dmcryan',\n",
       " 'lafebra',\n",
       " 'gfilche',\n",
       " 'storage',\n",
       " 'amp',\n",
       " 'easily',\n",
       " 'upgradable',\n",
       " 'avalonpenrose',\n",
       " 'httpstcodjdzxq',\n",
       " 'maz',\n",
       " 'couchinvestor',\n",
       " 'teslanews',\n",
       " 'wholemarsblog',\n",
       " 'yeah',\n",
       " 'months',\n",
       " 'wholemarsblog',\n",
       " 'drive',\n",
       " 'prnd',\n",
       " 'stalkstick',\n",
       " 'days',\n",
       " 'annoying',\n",
       " 'back',\n",
       " 'amp',\n",
       " 'shifter',\n",
       " 'wholemarsblog',\n",
       " 'stalks',\n",
       " 'car',\n",
       " 'guesses',\n",
       " 'drive',\n",
       " 'direction',\n",
       " 'based',\n",
       " 'obstacles',\n",
       " 'sees',\n",
       " 'context',\n",
       " 'amp',\n",
       " 'nav',\n",
       " 'map',\n",
       " 'httpstco',\n",
       " 'ehq',\n",
       " 'qy',\n",
       " 'avalonpenrose',\n",
       " 'hedge',\n",
       " 'fund',\n",
       " 'shorts',\n",
       " 'shrubbery',\n",
       " 'lafebra',\n",
       " 'gfilche',\n",
       " 'httpstcom',\n",
       " 'wwqstaxm',\n",
       " 'lafebra',\n",
       " 'gfilche',\n",
       " 'yeah',\n",
       " 'rear',\n",
       " 'screen',\n",
       " 'mph',\n",
       " 'trap',\n",
       " 'speed',\n",
       " 'mile',\n",
       " 'mph',\n",
       " 'top',\n",
       " 'speed',\n",
       " 'tires',\n",
       " 'production',\n",
       " 'car',\n",
       " 'achieve',\n",
       " 'mph',\n",
       " 'seconds',\n",
       " 'play',\n",
       " 'cyberpunk',\n",
       " 'plaid',\n",
       " 'model',\n",
       " 'ships',\n",
       " 'month',\n",
       " 'httpstcohfuptnqipb',\n",
       " 'discord',\n",
       " 'corpo',\n",
       " 'jason',\n",
       " 'yup',\n",
       " 'wild',\n",
       " 'times',\n",
       " 'discord',\n",
       " 'haha',\n",
       " 'httpstcof',\n",
       " 'fxqkbce',\n",
       " 'andycolt',\n",
       " 'waiting',\n",
       " 'faa',\n",
       " 'review',\n",
       " 'gamestonk',\n",
       " 'httpstcorztkdzaewj',\n",
       " 'labpadre',\n",
       " 'passed',\n",
       " 'initial',\n",
       " 'pressure',\n",
       " 'test',\n",
       " 'adamhoov',\n",
       " 'ppathole',\n",
       " 'httpstcov',\n",
       " 'cffwac',\n",
       " 'bought',\n",
       " 'hand',\n",
       " 'knit',\n",
       " 'wool',\n",
       " 'marvin',\n",
       " 'martian',\n",
       " 'helm',\n",
       " 'dog',\n",
       " 'httpstcogpcvjibtlm',\n",
       " 'kinda',\n",
       " 'love',\n",
       " 'etsy',\n",
       " 'thesheetztweetz',\n",
       " 'serve',\n",
       " 'public',\n",
       " 'hamstring',\n",
       " 'starlink',\n",
       " 'today',\n",
       " 'amazon',\n",
       " 'satellite',\n",
       " 'system',\n",
       " 'httpstcosnigkxdxfp',\n",
       " 'nextspaceflight',\n",
       " 'hoping',\n",
       " 'faa',\n",
       " 'approval',\n",
       " 'test',\n",
       " 'flight',\n",
       " 'tomorrow',\n",
       " 'afternoon',\n",
       " 'wholemarsblog',\n",
       " 'entire',\n",
       " 'stack',\n",
       " 'data',\n",
       " 'collection',\n",
       " 'labeling',\n",
       " 'amp',\n",
       " 'inference',\n",
       " 'surround',\n",
       " 'video',\n",
       " 'httpstcou',\n",
       " 'sqjkn',\n",
       " 'flcnhvy',\n",
       " 'wholemarsblog',\n",
       " 'crazy',\n",
       " 'turn',\n",
       " 'fsd',\n",
       " 'wholemarsblog',\n",
       " 'tesla',\n",
       " 'steadily',\n",
       " 'moving',\n",
       " 'nns',\n",
       " 'camera',\n",
       " 'surround',\n",
       " 'video',\n",
       " 'enable',\n",
       " 'superhuman',\n",
       " 'selfdriving',\n",
       " 'naval',\n",
       " 'road',\n",
       " 'hell',\n",
       " 'paved',\n",
       " 'bad',\n",
       " ...]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "df_token= word_tokenize(text_3)\n",
    "df_token\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911090d3",
   "metadata": {},
   "source": [
    "### \n",
    "Noramalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ef6bdfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kunalb', 'im', 'alien', 'idaacarmack', 'ray', 'tracing', 'cyberpunk', 'hdr', 'nextlevel', 'joerogan', 'spotify', 'great', 'interview', 'gtera', 'doge', 'underestimated', 'teslacn', 'congratulations', 'tesla', 'china', 'amazing', 'execution', 'year', 'happy', 'year']\n"
     ]
    }
   ],
   "source": [
    "lower_words = [x.lower() for x in df_token]\n",
    "print(lower_words[0:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e147cb66",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "537d936a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kunalb', 'im', 'alien', 'idaacarmack', 'ray', 'trace', 'cyberpunk', 'hdr', 'nextlevel', 'joerogan', 'spotifi', 'great', 'interview', 'gtera', 'doge', 'underestim', 'teslacn', 'congratul', 'tesla', 'china', 'amaz', 'execut', 'year', 'happi', 'year', 'ox', 'httpstco', 'wfkmyu', 'oj', 'frodo', 'underdogeal', 'thought', 'failhimself', 'httpstcozgxjfdzzrm', 'owenspark', 'flcnhvi', 'anonyx', 'haha', 'flcnhvi', 'anonyx']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "stemmed_tokens = [ps.stem(word) for word in lower_words]\n",
    "print(stemmed_tokens[0:40])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89327124",
   "metadata": {},
   "source": [
    "### removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e70c334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_stop_stemmed= [word for word in stemmed_tokens if not word in my_stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bdda6acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12963\n",
      "12869\n"
     ]
    }
   ],
   "source": [
    "print(len(stemmed_tokens))\n",
    "print(len(no_stop_stemmed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc43c399",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5ca129",
   "metadata": {},
   "source": [
    "Lemmatization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3a659cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kunalb im alien idaacarmack ray trace cyberpunk hdr nextlevel joerogan spotifi great interview gtera doge underestim teslacn congratul tesla china amaz execut year happi year ox httpstco wfkmyu oj frodo underdogeal thought failhimself httpstcozgxjfdzzrm owenspark flcnhvi anonyx haha flcnhvi\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# lemmas being one of them, but mostly POS, which will follow later\n",
    "doc = nlp(' '.join(no_stop_stemmed))\n",
    "print(doc[0:40])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "148b2adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kunalb', 'i', 'm', 'alien', 'idaacarmack', 'ray', 'trace', 'cyberpunk', 'hdr', 'nextlevel', 'joerogan', 'spotifi', 'great', 'interview', 'gtera', 'doge', 'underestim', 'teslacn', 'congratul', 'tesla', 'china', 'amaz', 'execut', 'year', 'happi']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "lemmas = [token.lemma_ for token in doc]\n",
    "print(lemmas[0:25])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c2bc8b",
   "metadata": {},
   "source": [
    "### \n",
    "feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ca1017f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<12960x4587 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 12895 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(lemmas)\n",
    "X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "15278749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12960, 4587)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f18bf5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ab</th>\n",
       "      <th>aber</th>\n",
       "      <th>abo</th>\n",
       "      <th>aboard</th>\n",
       "      <th>abort</th>\n",
       "      <th>absenc</th>\n",
       "      <th>absolut</th>\n",
       "      <th>absorb</th>\n",
       "      <th>absorpt</th>\n",
       "      <th>absurd</th>\n",
       "      <th>...</th>\n",
       "      <th>zshauladventur</th>\n",
       "      <th>zsyalvczx</th>\n",
       "      <th>ztn</th>\n",
       "      <th>zubinanari</th>\n",
       "      <th>zvm</th>\n",
       "      <th>zwiebelbach</th>\n",
       "      <th>zxd</th>\n",
       "      <th>zz</th>\n",
       "      <th>zzcool</th>\n",
       "      <th>ðogecoin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4587 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ab  aber  abo  aboard  abort  absenc  absolut  absorb  absorpt  absurd  \\\n",
       "0   0     0    0       0      0       0        0       0        0       0   \n",
       "1   0     0    0       0      0       0        0       0        0       0   \n",
       "2   0     0    0       0      0       0        0       0        0       0   \n",
       "3   0     0    0       0      0       0        0       0        0       0   \n",
       "4   0     0    0       0      0       0        0       0        0       0   \n",
       "\n",
       "   ...  zshauladventur  zsyalvczx  ztn  zubinanari  zvm  zwiebelbach  zxd  zz  \\\n",
       "0  ...               0          0    0           0    0            0    0   0   \n",
       "1  ...               0          0    0           0    0            0    0   0   \n",
       "2  ...               0          0    0           0    0            0    0   0   \n",
       "3  ...               0          0    0           0    0            0    0   0   \n",
       "4  ...               0          0    0           0    0            0    0   0   \n",
       "\n",
       "   zzcool  ðogecoin  \n",
       "0       0         0  \n",
       "1       0         0  \n",
       "2       0         0  \n",
       "3       0         0  \n",
       "4       0         0  \n",
       "\n",
       "[5 rows x 4587 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from PIL import Image\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "count_vect_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "59f32d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zbt</th>\n",
       "      <td>4557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zcf</th>\n",
       "      <td>4558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zczinfc</th>\n",
       "      <td>4559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zddfql</th>\n",
       "      <td>4560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zealand</th>\n",
       "      <td>4561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zeitma</th>\n",
       "      <td>4562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zenit</th>\n",
       "      <td>4563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zg</th>\n",
       "      <td>4564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zihfeg</th>\n",
       "      <td>4565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zikryzamir</th>\n",
       "      <td>4566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zip</th>\n",
       "      <td>4567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zk</th>\n",
       "      <td>4568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zlkc</th>\n",
       "      <td>4569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zmqgbo</th>\n",
       "      <td>4570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>znztmbj</th>\n",
       "      <td>4571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zogfotpik</th>\n",
       "      <td>4572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zon</th>\n",
       "      <td>4573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zone</th>\n",
       "      <td>4574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zq</th>\n",
       "      <td>4575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zr</th>\n",
       "      <td>4576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zshauladventur</th>\n",
       "      <td>4577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zsyalvczx</th>\n",
       "      <td>4578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ztn</th>\n",
       "      <td>4579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zubinanari</th>\n",
       "      <td>4580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zvm</th>\n",
       "      <td>4581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zwiebelbach</th>\n",
       "      <td>4582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zxd</th>\n",
       "      <td>4583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zz</th>\n",
       "      <td>4584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzcool</th>\n",
       "      <td>4585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ðogecoin</th>\n",
       "      <td>4586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0\n",
       "zbt             4557\n",
       "zcf             4558\n",
       "zczinfc         4559\n",
       "zddfql          4560\n",
       "zealand         4561\n",
       "zeitma          4562\n",
       "zenit           4563\n",
       "zg              4564\n",
       "zihfeg          4565\n",
       "zikryzamir      4566\n",
       "zip             4567\n",
       "zk              4568\n",
       "zlkc            4569\n",
       "zmqgbo          4570\n",
       "znztmbj         4571\n",
       "zogfotpik       4572\n",
       "zon             4573\n",
       "zone            4574\n",
       "zq              4575\n",
       "zr              4576\n",
       "zshauladventur  4577\n",
       "zsyalvczx       4578\n",
       "ztn             4579\n",
       "zubinanari      4580\n",
       "zvm             4581\n",
       "zwiebelbach     4582\n",
       "zxd             4583\n",
       "zz              4584\n",
       "zzcool          4585\n",
       "ðogecoin        4586"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_records([vectorizer.vocabulary_]).T.sort_values(0,ascending=True).head(30)\n",
    "pd.DataFrame.from_records([vectorizer.vocabulary_]).T.sort_values(0,ascending=True).tail(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8db375c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bi-gram</th>\n",
       "      <th>Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt spacex falcon</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spacex falcon stage</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thesheetztweetz waemd spacex</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jgrano teslaratiteam teslarati</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ppathole thesheetztweetz waemd</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Bi-gram  Freq\n",
       "0                rt spacex falcon    17\n",
       "1             spacex falcon stage     8\n",
       "2    thesheetztweetz waemd spacex     8\n",
       "3  jgrano teslaratiteam teslarati     8\n",
       "4  ppathole thesheetztweetz waemd     7"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bi-gram\n",
    "def get_top_n2_words(corpus,ngram_range, n=None):\n",
    "    vec1 = CountVectorizer(ngram_range=ngram_range,  #for tri-gram, put ngram_range=(3,3)\n",
    "            max_features=2000).fit(corpus)\n",
    "    bag_of_words = vec1.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in     \n",
    "                  vec1.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], \n",
    "                reverse=True)\n",
    "    return words_freq[:n]\n",
    "\n",
    "top2_words = get_top_n2_words(df[\"text\"],ngram_range=(3,3), n=200) #top 200\n",
    "top2_df = pd.DataFrame(top2_words)\n",
    "top2_df.columns=[\"Bi-gram\", \"Freq\"]\n",
    "top2_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f8f646f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rt spacex falcon', 17),\n",
       " ('spacex falcon stage', 8),\n",
       " ('thesheetztweetz waemd spacex', 8),\n",
       " ('jgrano teslaratiteam teslarati', 8),\n",
       " ('ppathole thesheetztweetz waemd', 7),\n",
       " ('waemd spacex spacexstarlink', 7),\n",
       " ('falcon stage landed', 6),\n",
       " ('rt spacex liftoff', 6),\n",
       " ('spacex spacexstarlink wanationalguard', 6),\n",
       " ('spacex felixschlang marcushousegame', 5),\n",
       " ('rt spacex dragon', 5),\n",
       " ('rt spacex crew', 5),\n",
       " ('neopork casparstanley ercxspace', 5),\n",
       " ('casparstanley ercxspace marcushousegame', 5),\n",
       " ('ercxspace marcushousegame felixschlang', 5),\n",
       " ('erdayastronaut joshbickett ajtourville', 4),\n",
       " ('joshbickett ajtourville spacex', 4),\n",
       " ('spacex falcon launches', 4),\n",
       " ('tjcooney lrocket spacex', 4),\n",
       " ('lrocket spacex felixschlang', 4),\n",
       " ('landed love droneship', 4),\n",
       " ('mirojurcevic tashaark spacestation', 4),\n",
       " ('dragons operational mission', 4),\n",
       " ('rt spacex deployment', 4),\n",
       " ('kristennetten boringcompany tesla', 4),\n",
       " ('brendan bocachicagal nasaspaceflight', 4),\n",
       " ('alexavoigt mikezimon wholemarsblog', 4),\n",
       " ('rationaletienne ppathole thesheetztweetz', 4),\n",
       " ('futurejurvetson cfsenergy cupplasma', 4),\n",
       " ('cfsenergy cupplasma mit', 4),\n",
       " ('ajtourville commaai tesmaniancom', 4),\n",
       " ('icannotenough flcnhvy tesla', 4),\n",
       " ('falcon launches starlink', 3),\n",
       " ('rt spacex watch', 3),\n",
       " ('spacex watch falcon', 3),\n",
       " ('watch falcon launch', 3),\n",
       " ('sn amp sn', 3),\n",
       " ('stage landed love', 3),\n",
       " ('rationaletienne biogirl ercxspace', 3),\n",
       " ('ppathole mirojurcevic tashaark', 3),\n",
       " ('icannotenough erdayastronaut rweb', 3),\n",
       " ('johnnacrider timmerenginerd jack', 3),\n",
       " ('nasa spacex crew', 3),\n",
       " ('crew dragons operational', 3),\n",
       " ('rt teslarati tesla', 3),\n",
       " ('austinteslaclub joetegtmeyer peterdog', 3),\n",
       " ('joetegtmeyer peterdog txterafactory', 3),\n",
       " ('peterdog txterafactory terafactorytx', 3),\n",
       " ('txterafactory terafactorytx lqdchkn', 3),\n",
       " ('tobyliiiiiiiiii austinbarnard superclusterhq', 3),\n",
       " ('marcushousegame felixschlang cbass', 3),\n",
       " ('felixschlang cbass nickhenning', 3),\n",
       " ('cbass nickhenning spacex', 3),\n",
       " ('marcushousegame brendan bocachicagal', 3),\n",
       " ('ihearttesla alexavoigt mikezimon', 3),\n",
       " ('erdayastronaut trevormahlmann johnkrausphotos', 3),\n",
       " ('trevormahlmann johnkrausphotos mikeseeley', 3),\n",
       " ('erdayastronaut nasaspaceflight bocachicagal', 3),\n",
       " ('nasaspaceflight bocachicagal thefavoritist', 3),\n",
       " ('model owners futurejurvetson', 3),\n",
       " ('owners futurejurvetson cfsenergy', 3),\n",
       " ('neopork spacex marcushousegame', 3),\n",
       " ('rykllan felixschlang spacexcentric', 3),\n",
       " ('felixschlang spacexcentric marcushousegame', 3),\n",
       " ('spacexcentric marcushousegame spacex', 3),\n",
       " ('tjmurphymit thesheetztweetz exploremars', 3),\n",
       " ('thesheetztweetz exploremars spacex', 3),\n",
       " ('exploremars spacex theespacedude', 3),\n",
       " ('nigellockyer penn fermilab', 3),\n",
       " ('kulpability tlowdon ethicalskeptic', 3),\n",
       " ('erdayastronaut spacetoday elonsworld', 3),\n",
       " ('spacetoday elonsworld felixschlang', 3),\n",
       " ('elonsworld felixschlang chrisgnsf', 3),\n",
       " ('felixschlang chrisgnsf djsnm', 3),\n",
       " ('erdayastronaut flcnhvy djsnm', 3),\n",
       " ('erdayastronaut dauqhx universalsci', 3),\n",
       " ('erdayastronaut queuemax nasaspaceflight', 3),\n",
       " ('spacestation astrobehnken astrodoug', 3),\n",
       " ('flcnhvy shravantr neuroskeptic', 3),\n",
       " ('teslaownerssv jgrano teslaratiteam', 3),\n",
       " ('flcnhvy ppathole ihearttesla', 3),\n",
       " ('havent heard years', 2),\n",
       " ('spacex falcon launch', 2),\n",
       " ('falcon launch nasas', 2),\n",
       " ('launches starlink satellites', 2),\n",
       " ('starlink satellites orbit', 2),\n",
       " ('ajtourville erdayastronaut spacex', 2),\n",
       " ('working super hard', 2),\n",
       " ('erdayastronaut tjcooney lrocket', 2),\n",
       " ('felixschlang marcushousegame tom', 2),\n",
       " ('marcushousegame tom great', 2),\n",
       " ('spacex targeting earlier', 2),\n",
       " ('iupsychdoctor aoc robinhoodapp', 2),\n",
       " ('making products amp', 2),\n",
       " ('megaconstellati aviationintel jetcitystar', 2),\n",
       " ('aviationintel jetcitystar larrypress', 2),\n",
       " ('hardware amp software', 2),\n",
       " ('rt spacex spacexs', 2),\n",
       " ('erdayastronaut spacex sn', 2),\n",
       " ('tesla spacex neuralink', 2),\n",
       " ('thing call money', 2),\n",
       " ('splashdown dragon confirmed', 2),\n",
       " ('lot happened years', 2),\n",
       " ('rt spacex separation', 2),\n",
       " ('spacex separation confirmed', 2),\n",
       " ('separation confirmed dragon', 2),\n",
       " ('confirmed dragon performing', 2),\n",
       " ('dragon performing departure', 2),\n",
       " ('performing departure burns', 2),\n",
       " ('departure burns move', 2),\n",
       " ('burns move spacestation', 2),\n",
       " ('sean erdayastronaut spacex', 2),\n",
       " ('fusion reactor sky', 2),\n",
       " ('erdayastronaut flcnhvy ercxspace', 2),\n",
       " ('final days year', 2),\n",
       " ('products amp services', 2),\n",
       " ('teslatruckclub jeremyjudkins jpuconn', 2),\n",
       " ('jeremyjudkins jpuconn jchybow', 2),\n",
       " ('jpuconn jchybow dirtytesla', 2),\n",
       " ('medium range cars', 2),\n",
       " ('rt spacex photos', 2),\n",
       " ('httpstco whx bx', 2),\n",
       " ('whx bx httpstco', 2),\n",
       " ('stage landed landing', 2),\n",
       " ('landed landing zone', 2),\n",
       " ('tesmaniancom dankeschön brandenburg', 2),\n",
       " ('rt spacex starship', 2),\n",
       " ('orbit completing spacexs', 2),\n",
       " ('ppathole ercxspace spacex', 2),\n",
       " ('header tank pressure', 2),\n",
       " ('cargo resupply mission', 2),\n",
       " ('spacex falcon booster', 2),\n",
       " ('erdayastronaut marcushousegame felixschlang', 2),\n",
       " ('bcart nextspaceflight nasaspaceflight', 2),\n",
       " ('nextspaceflight nasaspaceflight static', 2),\n",
       " ('nasaspaceflight static fire', 2),\n",
       " ('johneg teslachillmode unplgd', 2),\n",
       " ('teslachillmode unplgd mfrunker', 2),\n",
       " ('unplgd mfrunker ccteslaclub', 2),\n",
       " ('rapid amp complete', 2),\n",
       " ('ppathole teslarati teslaroadtrip', 2),\n",
       " ('tobyliiiiiiiiii spacex nasa', 2),\n",
       " ('spacex nasa nasalsp', 2),\n",
       " ('nasa nasalsp nasajpl', 2),\n",
       " ('nasalsp nasajpl esa', 2),\n",
       " ('evafoxu ppathole mirojurcevic', 2),\n",
       " ('teslaownerssv weeks release', 2),\n",
       " ('erdayastronaut rweb yeah', 2),\n",
       " ('joshbickett icannotenough erdayastronaut', 2),\n",
       " ('erdayastronaut charlesnotrumps rweb', 2),\n",
       " ('spacex crew astronauts', 2),\n",
       " ('spacex dragon spacecraft', 2),\n",
       " ('rt nasa live', 2),\n",
       " ('spacex crew mission', 2),\n",
       " ('operational mission astronauts', 2),\n",
       " ('ppathole astrojordy erujabidi', 2),\n",
       " ('nickhenning spacex ercxspace', 2),\n",
       " ('spacex ercxspace neopork', 2),\n",
       " ('ercxspace neopork cbass', 2),\n",
       " ('neopork cbass casparstanley', 2),\n",
       " ('cbass casparstanley spacexvision', 2),\n",
       " ('casparstanley spacexvision felixschlang', 2),\n",
       " ('spacex crew dragon', 2),\n",
       " ('linustech spacexstarlink spacex', 2),\n",
       " ('falcon stage lands', 2),\n",
       " ('chadhurley realdonaldtrump kanyewest', 2),\n",
       " ('zainraz vincent jonerlichman', 2),\n",
       " ('steezyysosa austinteslaclub joetegtmeyer', 2),\n",
       " ('terafactorytx lqdchkn jdaverage', 2),\n",
       " ('klotzadam nasaspaceflight erdayastronaut', 2),\n",
       " ('toadmeister sweden deaths', 2),\n",
       " ('sweden deaths oct', 2),\n",
       " ('converts million tons', 2),\n",
       " ('million tons mass', 2),\n",
       " ('tons mass energy', 2),\n",
       " ('phased array antenna', 2),\n",
       " ('tesla team great', 2),\n",
       " ('team great work', 2),\n",
       " ('erdayastronaut tobyliiiiiiiiii austinbarnard', 2),\n",
       " ('ppathole teslaownerssv teslaraj', 2),\n",
       " ('bar chamber pressure', 2),\n",
       " ('wholemarsblog kristennetten boringcompany', 2),\n",
       " ('st cargo resupply', 2),\n",
       " ('mariabartiromo potus realdonaldtrump', 2),\n",
       " ('potus realdonaldtrump jeffbezos', 2),\n",
       " ('realdonaldtrump jeffbezos morningsmaria', 2),\n",
       " ('jeffbezos morningsmaria foxbusiness', 2),\n",
       " ('flcnhvy neopork casparstanley', 2),\n",
       " ('nickhenning spacex tiles', 2),\n",
       " ('model long range', 2),\n",
       " ('franktinsley ankitxupta tashaark', 2),\n",
       " ('mikezimon wholemarsblog tasty', 2),\n",
       " ('chananbos raytech wholemarsblog', 2),\n",
       " ('sandy munro understands', 2),\n",
       " ('munro understands engineering', 2),\n",
       " ('teslaownerssv raytech wholemarsblog', 2),\n",
       " ('klodua erdayastronaut trevormahlmann', 2),\n",
       " ('spacex deployment starlink', 2),\n",
       " ('deployment starlink satellites', 2),\n",
       " ('starlink satellites confirmed', 2)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_n2_words(df[\"text\"],ngram_range=(3,3), n=200) #trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e620a04e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only supported for TrueType fonts",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12680/1069175304.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtxt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mwc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackground_color\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'white'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m700\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    637\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m         \"\"\"\n\u001b[1;32m--> 639\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_generated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    619\u001b[0m         \"\"\"\n\u001b[0;32m    620\u001b[0m         \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 621\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_frequencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    622\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_frequencies\u001b[1;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[0;32m    451\u001b[0m                 \u001b[0mfont_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m                 self.generate_from_frequencies(dict(frequencies[:2]),\n\u001b[0m\u001b[0;32m    454\u001b[0m                                                max_font_size=self.height)\n\u001b[0;32m    455\u001b[0m                 \u001b[1;31m# find font sizes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_frequencies\u001b[1;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[0;32m    506\u001b[0m                     font, orientation=orientation)\n\u001b[0;32m    507\u001b[0m                 \u001b[1;31m# get size of resulting text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 508\u001b[1;33m                 \u001b[0mbox_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtextbbox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfont\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransposed_font\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manchor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"lt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    509\u001b[0m                 \u001b[1;31m# find possible places using integral image:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m                 result = occupancy.sample_position(box_size[3] + self.margin,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PIL\\ImageDraw.py\u001b[0m in \u001b[0;36mtextbbox\u001b[1;34m(self, xy, text, font, anchor, spacing, align, direction, features, language, stroke_width, embedded_color)\u001b[0m\n\u001b[0;32m    649\u001b[0m             \u001b[0mfont\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetfont\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mImageFont\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFreeTypeFont\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Only supported for TrueType fonts\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m         \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"RGBA\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0membedded_color\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfontmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m         bbox = font.getbbox(\n",
      "\u001b[1;31mValueError\u001b[0m: Only supported for TrueType fonts"
     ]
    }
   ],
   "source": [
    "txt = ' '.join(df['text'])\n",
    "\n",
    "wc = WordCloud(background_color='white', width=700, height=500).generate(txt)\n",
    "\n",
    "plt.imshow(wc)\n",
    "plt.axis('off')\n",
    "plt.title('WordCloud',size = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7d0644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af85c911",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
